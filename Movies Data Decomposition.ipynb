{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Movies data processing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import  *\n",
    "from pyspark.sql.functions import col, from_json, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_folder = 'datasets'\n",
    "hadoop_dest_folder = 'hdfs://192.168.56.101:9000/obligatorio/processed_tables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_normalized_tables(df,entity_name, entity_identifier = \"id\"):\n",
    "    sub_df = df.select([\"id\",entity_name])\n",
    "    sub_df = sub_df.filter(sub_df[entity_name].isNotNull())\n",
    "    rdd = sub_df.rdd\n",
    "    movie_entity = rdd.flatMap(lambda r: map(lambda g: (r.id, g[entity_identifier]), r[entity_name]))\n",
    "    entity = rdd.flatMap(lambda r: r[entity_name])\n",
    "    entity = entity.map(tuple)\n",
    "    entity = entity.reduceByKey(lambda a, b : a)\n",
    "    return entity, movie_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_rdd(rdd, fields, table_name):\n",
    "    df = rdd.toDF(fields)\n",
    "    df.write.mode('overwrite').parquet(f'{hadoop_dest_folder}/{table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de dataset de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"escape\",\"\\\"\").option(\"quote\",\"\\\"\").load(f'{hadoop_folder}/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ba0aff1ba512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.dropDuplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unión con ratings promedios calculados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumando las cantidades de votes_count por pelicula, se puede ver que son 5 millones de votos en total, por lo tanto, aporta mas informacion utilizar el calculo de promedio de ratings con 26 millones de registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "movies.select(F.sum('vote_count')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_schema = StructType([\n",
    "    StructField(\"movie_id\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.format(\"csv\").option(\"header\", \"true\").schema(ratings_schema).load('hdfs://192.168.56.101:9000/obligatorio/ratings', header=False)\n",
    "links = spark.read.format(\"csv\").option(\"header\", \"true\").load('hdfs://192.168.56.101:9000/obligatorio/datasets/links.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.na.drop(subset=[\"movie_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.dropDuplicates(subset=['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.withColumn(\"movieId\", (links.movieId).cast(\"Integer\"))\\\n",
    "             .withColumn(\"imdbId\", (links.imdbId).cast(\"Integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.join(links, ratings.movie_id == links.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.withColumn(\"movie_id\", (ratings.tmdbId).cast(\"Integer\"))\\\n",
    "                 .withColumn(\"rating\", (ratings.rating).cast(\"Float\"))[\"movie_id\", \"rating\"]\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.dropDuplicates(subset=['movie_id'])\n",
    "ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formateo de atributos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_adult = \"adult\"\n",
    "a_belongs_to = \"belongs_to_collection\"\n",
    "a_budget = \"budget\"\n",
    "a_genres = \"genres\"\n",
    "a_id = \"id\"\n",
    "a_original_language = \"original_language\"\n",
    "a_original_title = \"original_title\"\n",
    "a_overview = \"overview\"\n",
    "a_popularity = \"popularity\"\n",
    "a_prod_companies = \"production_companies\"\n",
    "a_production_countries = \"production_countries\"\n",
    "a_release_date = \"release_date\"\n",
    "a_revenue = \"revenue\"\n",
    "a_spoken_languages = \"spoken_languages\"\n",
    "a_title = \"title\"\n",
    "a_vote_average = \"vote_average\"\n",
    "a_vote_count = \"vote_count\"\n",
    "a_rating = \"rating\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante definir los esquemas para los atributos en formato json, para poder parsearlos. \n",
    "En los archivos csv se guardan como texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_schema = ArrayType(\n",
    "    StructType([StructField(\"id\", IntegerType()), \n",
    "                StructField(\"name\", StringType())]))\n",
    "\n",
    "prod_companies_schema = ArrayType(\n",
    "    StructType([StructField(\"name\", StringType()),\n",
    "                StructField(\"id\", IntegerType())]))\n",
    "\n",
    "prod_countries_schema = ArrayType(\n",
    "    StructType([StructField(\"iso_3166_1\", StringType()),\n",
    "                StructField(\"name\", StringType())]))\n",
    "\n",
    "spoken_languages_schema = ArrayType(\n",
    "    StructType([StructField(\"iso_639_1\", StringType()),\n",
    "                StructField(\"name\", StringType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn(\"adult\", (movies.adult).cast(\"Boolean\"))\\\n",
    "         .withColumn(\"movie_id\", (movies.id).cast(\"Integer\"))\\\n",
    "         .withColumn(\"budget\", (movies.budget).cast(\"Integer\"))\\\n",
    "         .withColumn(\"genres\", from_json(movies.genres, genres_schema))\\\n",
    "         .withColumn(\"production_companies\", from_json(movies.production_companies, prod_companies_schema))\\\n",
    "         .withColumn(\"production_countries\", from_json(movies.production_countries, prod_countries_schema))\\\n",
    "         .withColumn(\"spoken_languages\", from_json(movies.spoken_languages, spoken_languages_schema))\\\n",
    "         .withColumn(\"popularity\", (movies.popularity).cast(\"Float\"))\\\n",
    "         .withColumn(\"release_date\", (movies.release_date).cast(\"Date\"))\\\n",
    "         .withColumn(\"revenue\", (movies.revenue).cast(\"Integer\"))\\\n",
    "         .withColumn(\"vote_average\", (movies.vote_average).cast(\"Float\"))\\\n",
    "         .withColumn(\"vote_count\", (movies.vote_count).cast(\"Integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.join(ratings, on=['movie_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre, movie_genre = separate_normalized_tables(movies,\"genres\")\n",
    "prod_company, movie_prod_company = separate_normalized_tables(movies,\"production_companies\")\n",
    "country, movie_prod_country = separate_normalized_tables(movies, \"production_countries\", \"iso_3166_1\")\n",
    "language, movie_spoken_language = separate_normalized_tables(movies, \"spoken_languages\", \"iso_639_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields = [a_adult, a_budget, a_id, a_original_language, \n",
    "    a_original_title, a_overview, a_popularity, a_release_date, \n",
    "    a_revenue, a_title, a_vote_average, a_vote_count, a_rating]\n",
    "\n",
    "movies = movies[selected_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.write.mode('overwrite').parquet(f'{hadoop_dest_folder}/movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_movies = \"movies\"\n",
    "t_genres = \"genres\"\n",
    "t_movies_genres = \"movies_genres\"\n",
    "t_prod_companies = \"prod_companies\"\n",
    "t_movies_prod_companies = \"movies_prod_companies\"\n",
    "t_countries = \"prod_countries\"\n",
    "t_movies_countries = \"movies_prod_countries\"\n",
    "t_languages = \"spoken_languages\"\n",
    "t_movies_languages = \"movies_spoken_languages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_rdd(genre, [\"id\", \"name\"], t_genres)\n",
    "store_rdd(movie_genre, [\"id_movie\", \"id_genre\"], t_movies_genres)\n",
    "store_rdd(prod_company, [\"id\", \"name\"], t_prod_companies)\n",
    "store_rdd(movie_prod_company, [\"id_movie\", \"id_prod_company\"], t_movies_prod_companies)\n",
    "store_rdd(country, [\"id\", \"name\"], t_countries)\n",
    "store_rdd(movie_prod_country, [\"id_movie\", \"id_prod_country\"], t_movies_countries)\n",
    "store_rdd(language, [\"id\", \"name\"], t_languages)\n",
    "store_rdd(movie_spoken_language, [\"id_movie\", \"id_spoken_language\"], t_movies_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Keywords Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"escape\",\"\\\"\").load(\"datasets/keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_id = \"id\"\n",
    "a_keywords = \"keywords\"\n",
    "\n",
    "\n",
    "keywords_schema = ArrayType(\n",
    "    StructType([StructField(\"id\", IntegerType()), \n",
    "                StructField(\"name\", StringType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = keywords.withColumn(\"id\", (keywords.id).cast(\"Integer\"))\\\n",
    "                   .withColumn(\"keywords\", from_json(keywords.keywords, keywords_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword, movie_keyword = separate_normalized_tables(keywords,\"keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_keyword = \"keywords\"\n",
    "t_movies_keywords = \"movies_keywords\"\n",
    "\n",
    "store_rdd(keyword, [\"id\", \"name\"], t_keyword)\n",
    "store_rdd(movie_keyword, [\"id_movie\", \"id_keyword\"], t_movies_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Credits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"escape\",\"\\\"\").load(\"datasets/credits.csv\")\n",
    "credits = credits.withColumn('cast', regexp_replace('cast', ': None', \": ''\"))\n",
    "credits = credits.withColumn('crew', regexp_replace('crew', ': None', \": ''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_id = \"id\"\n",
    "a_cast = \"cast\"\n",
    "a_crew = \"crew\"\n",
    "\n",
    "\n",
    "crew_schema = ArrayType(\n",
    "    StructType([StructField(\"credit_id\", StringType()), \n",
    "                StructField(\"department\", StringType()),\n",
    "                StructField(\"gender\", IntegerType()),\n",
    "                StructField(\"id\", IntegerType()),\n",
    "                StructField(\"job\", StringType()),\n",
    "                StructField(\"name\", StringType()),\n",
    "                StructField(\"profile_path\", StringType())\n",
    "               ]))\n",
    "\n",
    "cast_schema = ArrayType(\n",
    "    StructType([StructField(\"cast_id\", IntegerType()), \n",
    "                StructField(\"character\", StringType()),\n",
    "                StructField(\"credit_id\", StringType(), True),\n",
    "                StructField(\"gender\", IntegerType(), True),\n",
    "                StructField(\"id\", IntegerType()),\n",
    "                StructField(\"name\", StringType()),\n",
    "                StructField(\"order\", IntegerType(), True),\n",
    "                StructField(\"profile_path\", StringType(), True),\n",
    "               ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = credits.withColumn(\"id\", (credits.id).cast(\"Integer\"))\\\n",
    "                  .withColumn(\"cast\", from_json(credits.cast, cast_schema))\\\n",
    "                  .withColumn(\"crew\", from_json(credits.crew, crew_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = credits.select([\"id\",\"cast\"])\n",
    "sub_df = sub_df.filter(sub_df[\"cast\"].isNotNull())\n",
    "rdd = sub_df.rdd\n",
    "movie_cast = rdd.flatMap(lambda r: map(lambda g: (r.id, g[\"id\"]), r[\"cast\"]))\n",
    "cast = rdd.flatMap(lambda r: r[\"cast\"])\n",
    "cast = rdd.flatMap(lambda r: r[\"cast\"])\n",
    "cast = cast.map(lambda e: (e.id, (e.cast_id, e.character, e.gender, e.name, e.order)))\n",
    "cast = cast.reduceByKey(lambda a, b : a)\n",
    "cast = cast.map(lambda t: (t[0], t[1][0], t[1][1], t[1][2], t[1][3], t[1][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cast = \"cast\"\n",
    "t_movies_cast = \"movies_cast\"\n",
    "\n",
    "store_rdd(cast, [\"id\", \"cast_id\", \"character\", \"gender\", \"name\", \"order\"], t_cast)\n",
    "store_rdd(movie_cast, [\"id_movie\", \"cast_id\"], t_movies_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = credits.select([\"id\",\"crew\"])\n",
    "sub_df = sub_df.filter(sub_df[\"crew\"].isNotNull())\n",
    "rdd = sub_df.rdd\n",
    "movie_crew = rdd.flatMap(lambda r: map(lambda g: (r.id, g[\"id\"]), r[\"crew\"]))\n",
    "crew = rdd.flatMap(lambda r: r[\"crew\"])\n",
    "crew = crew.map(lambda e: (e.id, (e.department, e.gender, e.job)))\n",
    "crew = crew.reduceByKey(lambda a, b : a)\n",
    "crew = crew.map(lambda t: (t[0], t[1][0], t[1][1], t[1][2]))\n",
    "cast.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_crew = \"crew\"\n",
    "t_movie_crew = \"movies_crew\"\n",
    "\n",
    "store_rdd(crew, [\"id\", \"department\", \"gender\", \"job\"], t_crew)\n",
    "store_rdd(movie_crew, [\"id_movie\", \"crew_id\"], t_movie_crew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
